{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0994256",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run constants.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70b37d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "\n",
    "def calculate_summary_statistics(analysis_df):\n",
    "    \"\"\"\n",
    "    Given the CP losses and accuracies for each player for a game, calculate their ACPL and\n",
    "    overall % accuracy then collate and return the summaries for both\n",
    "\n",
    "    :param analysis: Analysis\n",
    "    \"\"\"\n",
    "    # Extract the engine name\n",
    "    game_id = analysis_df.iloc[0][\"game_id\"]\n",
    "    engine = analysis_df.iloc[0][\"engine\"]\n",
    "    depth = analysis_df.iloc[0][\"depth\"]\n",
    "\n",
    "    summary_df = pd.DataFrame(columns=[\n",
    "        \"game_id\",\n",
    "        \"engine\",\n",
    "        \"depth\",\n",
    "        \"player\",\n",
    "        \"acpl\",\n",
    "        \"accuracy\",\n",
    "        \"elo\",\n",
    "        \"dubious\",\n",
    "        \"mistakes\",\n",
    "        \"blunders\"])\n",
    "\n",
    "    for player in [WHITE, BLACK]:\n",
    "        # Extract the analysis for this player\n",
    "        player_analysis_df = analysis_df[analysis_df[\"player\"] == player]\n",
    "        cp_losses = player_analysis_df[\"cpl\"].tolist()\n",
    "        accuracies = player_analysis_df.loc[player_analysis_df[\"accuracy\"] > 0, \"accuracy\"].tolist()\n",
    "        annotations = player_analysis_df[\"annotation\"].tolist()\n",
    "\n",
    "        #Â Calculate the ACPL, overall accuracy and estimated ELO\n",
    "        acpl = statistics.mean(cp_losses)\n",
    "        accuracy = statistics.harmonic_mean(accuracies)\n",
    "        elo = int(3100.0 * math.exp(-0.001 * acpl))\n",
    "\n",
    "        # Calculate the counts for each annotation type\n",
    "        dubious = len([a for a in annotations if a == \"?!\"])\n",
    "        mistakes = len([a for a in annotations if a == \"?\"])\n",
    "        blunders = len([a for a in annotations if a == \"??\"])\n",
    "\n",
    "        summary_df.loc[len(summary_df)] = [\n",
    "            game_id,\n",
    "            engine,\n",
    "            depth,\n",
    "            player,\n",
    "            acpl,\n",
    "            accuracy,\n",
    "            elo,\n",
    "            dubious,\n",
    "            mistakes,\n",
    "            blunders\n",
    "        ]\n",
    "\n",
    "    return summary_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
